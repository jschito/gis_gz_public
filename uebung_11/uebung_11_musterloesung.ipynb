{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIS GZ – Übung 11: Datenanalyse II <span style=\"color:red\">(Musterlösung)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grobziele\n",
    "* Sie können überprüfen, ob ein Phänomen zufällig im Raum verteilt ist oder nicht. \n",
    "\n",
    "### Feinziele\n",
    "* Sie können die Funktionsweise und Aussagen von Moran's I und Average Nearest Neighbor beschreiben und erklären.\n",
    "* Sie können Moran's I und Average Nearest Neighbor implementieren und Punktdaten auf Autokorrelation hin analysieren.\n",
    "\n",
    "### Projekt\n",
    "* Sie arbeiten an Ihrem Projekt und fokussieren auf die Datenanalyse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einleitung\n",
    "In der heutigen Übung betrachten wir die Verteilung von Punktdaten. Insbesondere interessiert uns, ob die Datenpunkte zufällig im Raum verteilt sind oder nicht. Wenn uns nur die Lage der Datenpunkte, nicht aber ihre Attributwerte interessiert, können wir dazu `Average Nearest Neighbor` verwenden. Falls wir untersuchen wollen, ob die Lage und die Attributwerte miteinander in einer Verbindung stehen, so verwenden wir dazu `Moran's I`. \n",
    "\n",
    "### Dateien\n",
    "In der heutigen Übung verwenden wir generisch generierte Punkte direkt in Jupyter Notebook, also ohne eine Datei zu importieren. Tipp: Wir haben jeweils die Standardnormalverteilung gewählt, um die Attributwerte zu samplen. Sie dürfen jedoch die Verteilungen anpassen und beobachten, was sich am Resultat ändert. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globale Settings\n",
    "#### Import-Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors.kd_tree import KDTree\n",
    "from ipywidgets import interactive, interact\n",
    "import ipywidgets as widgets\n",
    "import scipy.stats as st\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wichtige Variablen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 80\n",
    "width = 6\n",
    "height = 8\n",
    "std_dev = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hilfsfunktionen\n",
    "#### Distanzfunktion\n",
    "Dies ist eine simple Distanzfunktion, welche die gemessene Distanz in Relation zur maximalen Distanz setzt. Je kleiner die Distanz, desto näher ist das Gewicht bei 1; je weiter die Distanz, desto eher ist es bei 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_weight(point_i, point_j, max_distance):\n",
    "    current_distance = math.sqrt((point_i[0]-point_j[0])**2 + (point_i[1]-point_j[1])**2)\n",
    "    ratio = current_distance / max_distance\n",
    "    result = 1 - ratio\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotfunktion\n",
    "Damit werden die Punkte und die berechneten Werte geplottet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ann(sampling):\n",
    "\n",
    "    if sampling == \"random\":\n",
    "        xs = np.random.uniform(0, width, n)\n",
    "        ys = np.random.uniform(0, height, n)\n",
    "        zs = np.random.normal(0, std_dev, n)  # add a normally distributed column\n",
    "        pts = np.vstack((xs, ys, zs)).T\n",
    "\n",
    "    elif sampling == \"clustered\":\n",
    "        centers = [(5, 3), (2, 4)]\n",
    "        cluster_std = [0.3, 0.5]\n",
    "\n",
    "        pts, c = make_blobs(n_samples=n, cluster_std=cluster_std, centers=centers, n_features=2, random_state=0)\n",
    "        pts = np.insert(pts, 2, np.random.normal(0, std_dev, n), axis=1)  # add a normally distributed column\n",
    "\n",
    "    elif sampling == \"regular\":\n",
    "        nx = int(np.sqrt(n * 1.9))\n",
    "        X, Y = np.mgrid[0:width:complex(0, nx), 0:height:complex(0, nx)]\n",
    "        pts = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "        pts = np.insert(pts, 2, np.random.normal(0, std_dev, X.size), axis=1)  # add a normally distributed column\n",
    "\n",
    "        idx = np.random.choice(pts.shape[0], n, replace=False)\n",
    "        pts = pts[idx, :]\n",
    "    \n",
    "    \n",
    "    # Compute Moran's I\n",
    "    mi = compute_morans_i(pts)\n",
    "    if isinstance(mi, float):\n",
    "        mi = round(mi, 4)\n",
    "        \n",
    "    # Compute ANN\n",
    "    mins = np.min(pts, axis=0)\n",
    "    maxs = np.max(pts, axis=0)\n",
    "\n",
    "    N = pts.shape[0]\n",
    "    A = (maxs[0] - mins[0]) * (maxs[1] - mins[1])\n",
    "\n",
    "    # Calculate expected distance\n",
    "    D_e = 0.5 / np.sqrt(N / A)\n",
    "\n",
    "    # Calculate observed distance\n",
    "    tree = KDTree(pts, leaf_size=2)\n",
    "    dist, _ = tree.query(pts, k=2)\n",
    "    D_o = np.mean(dist, axis=0)[1]\n",
    "\n",
    "    ANN = D_o / D_e\n",
    "    \n",
    "    s = 0.26136 / np.sqrt(N**2 / A)\n",
    "    z_score = (D_o - D_e) / s\n",
    "    \n",
    "    p_value = 1.0 - st.norm.cdf(z_score) \n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "\n",
    "    cluster_trend = \"Clustering (ANN < 1)\"\n",
    "    if ANN > 1:\n",
    "        cluster_trend = \"Dispersion (ANN > 1)\"\n",
    "\n",
    "    # Z: {} P: {}\n",
    "\n",
    "    plt.title(\"Moran's I: {}  ||  {}: ANN: {} --> Trend: {}\".format(mi, \n",
    "                                                                    sampling.capitalize(),\n",
    "                                                                    round(ANN, 4),\n",
    "                                                                    cluster_trend,\n",
    "                                                                    round(z_score, 2),\n",
    "                                                                    round(p_value, 2)))\n",
    "\n",
    "    # Data points\n",
    "    plt.scatter(pts[:, 0],\n",
    "                pts[:, 1],\n",
    "                s=12,\n",
    "                c=pts[:, 2],    # COMMENT/UNCOMMENT THIS LINE TO DISTINGUISH THE Z VALUES BY COLOR\n",
    "                cmap='Purples'\n",
    "               )\n",
    "\n",
    "    plt.xlim(mins[0] - 0.5, maxs[0] + 0.5)\n",
    "    plt.ylim(mins[1] - 0.5, maxs[1] + 0.5)\n",
    "\n",
    "    # ax = ...\n",
    "    text = plt.text(0,0, \"\", va=\"bottom\", ha=\"left\")\n",
    "\n",
    "    def onclick(event):\n",
    "        tx = 'button=%d, x=%d, y=%d, xdata=%f, ydata=%f' % (event.button, event.x, event.y, event.xdata, event.ydata)\n",
    "        text.set_text(tx)\n",
    "\n",
    "    cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgaben\n",
    "### Moran's I\n",
    "In der folgenden Funktion haben wir Ihnen die Werte des XYZ-Arrays in drei separate Listen gepackt, was das Iterieren durch die einzelnen Punkte erleichtert. Implementieren Sie nun selbstständig die Funktion, die Ihnen Moran's I berechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_morans_i(pts):\n",
    "    mins = np.min(pts, axis=0)\n",
    "    maxs = np.max(pts, axis=0)\n",
    "    max_distance = math.sqrt((maxs[0]-mins[0])**2 + (maxs[1]-mins[1])**2)\n",
    "    \n",
    "    X = pts[:, 0]\n",
    "    X = X.tolist()\n",
    "    Y = pts[:, 1]\n",
    "    Y = Y.tolist()\n",
    "    Z = pts[:, 2]\n",
    "    Z = Z.tolist()\n",
    "    \n",
    "    n = len(X)\n",
    "    x_dash = sum(Z) / len(Z)\n",
    "    \n",
    "    sum_of_weights = 0\n",
    "    upper_part = 0\n",
    "    lower_part = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        point_i = (X[i], Y[i])\n",
    "        x_i = Z[i]\n",
    "        x_i_diff = x_i - x_dash\n",
    "        lower_part += x_i_diff ** 2\n",
    "        \n",
    "        for j in range(n):\n",
    "            point_j = (X[j], Y[j])\n",
    "            x_j = Z[j]\n",
    "            x_j_diff = x_j - x_dash\n",
    "            \n",
    "            # Continue, if the points are equal\n",
    "            if point_i == point_j:\n",
    "                continue\n",
    "        \n",
    "            w_i_j = compute_distance_weight(point_i, point_j, max_distance)\n",
    "            sum_of_weights += w_i_j\n",
    "            \n",
    "            product = w_i_j * x_i_diff * x_j_diff\n",
    "            upper_part += product\n",
    "            \n",
    "    morans_i = n / sum_of_weights * upper_part / lower_part\n",
    "    return morans_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ausprobieren der interaktive Ausgabefunktion\n",
    "Aufgrund der Einstellungen oben können Sie hier wählen, ob Sie die Punkteverteilung geclustert, homogen oder zufällig möchten. Beobachten Sie, wie sich die Werte anhand der Punkteverteilung ändern. Wenn Sie Moran's I implementiert haben, so testen Sie auch, ob und was sich ändert, wenn Sie statt der Normalverteilung eine andere Verteilung wählen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec3348ec22948e7a149775359cd61d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Number:', index=1, options=('random', 'clustered', 'regular'), val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_ann(sampling)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(plot_ann,\n",
    "         sampling=widgets.Dropdown(\n",
    "             options=['random', 'clustered', 'regular'],\n",
    "             value='clustered',\n",
    "             description='Number:',\n",
    "             disabled=False,)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
